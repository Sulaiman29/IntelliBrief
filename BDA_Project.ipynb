{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sulaiman29/IntelliBrief/blob/main/BDA_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sgk8xh0slXo"
      },
      "outputs": [],
      "source": [
        "pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge-score"
      ],
      "metadata": {
        "id": "rNz124ueceoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from scipy import spatial\n",
        "from statistics import mean\n",
        "from math import ceil\n",
        "from rouge_score import rouge_scorer\n",
        "import os"
      ],
      "metadata": {
        "id": "0kEtEt48cww9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4oXdYRXLc_hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/"
      ],
      "metadata": {
        "id": "AkIOwBhsdD31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_skipgram = fasttext.load_model(\"models/model_skipgram.bin\")\n",
        "model_cbow = fasttext.load_model(\"models/model_cbow.bin\")"
      ],
      "metadata": {
        "id": "kLzD7fHedwa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Provide the path to your PNG file\n",
        "image_path = '/content/473172_1_En_16_Fig1_HTML.png'\n",
        "\n",
        "# Display the image\n",
        "Image(filename=image_path)\n"
      ],
      "metadata": {
        "id": "vOyZKhuIdy_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/NLP.zip -d /content/data"
      ],
      "metadata": {
        "id": "bDHmA-2DeGeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive baye's classifier:\n",
        "import pandas as pd #Dataframe Manipulation library\n",
        "import numpy as np #Data Manipulation library\n",
        "\n",
        "#sklearn modules for Feature Extraction & Modelling\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#Libraries for Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from pylab import boxplot, text\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "import glob"
      ],
      "metadata": {
        "id": "BU_Krw-Gd-g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current working directory is: {os.getcwd()}\")\n",
        "dir = os.chdir(\"/content\")\n",
        "print(f'Changing directory to {os.getcwd()}')"
      ],
      "metadata": {
        "id": "JE4u2w7fe2NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(folder_names, root_path):\n",
        "    fileNames = [path + \"/data/BBC News Summary/News Articles/\" + folder + '/' + \"*.txt\"\n",
        "        for path,folder in zip([root_path]*len(folder_names), folder_names)]\n",
        "    #print(fileNames)\n",
        "    #print(\"\\n\")\n",
        "    doc_list = []\n",
        "    tags = folder_names\n",
        "    for docs in fileNames:\n",
        "        #print(docs)\n",
        "        doc = glob.glob(docs)#glob method iterates through all files and reads the text in documents in the folders\n",
        "        for text in doc:\n",
        "            with open(text, encoding=\"latin-1\") as f:\n",
        "                topic = docs.split('/')[len(docs.split('/'))-2]\n",
        "                lines = f.readlines()\n",
        "                heading = lines[0].strip()#stripping the text by spaces and using first element into heading\n",
        "                body = ' '.join([l.strip() for l in lines[1:]])\n",
        "                doc_list.append([topic,heading,body])\n",
        "        print(f\"Loading data from \\033[1m{topic}\\033[0m directory\")\n",
        "    print(\"\\nEntire Data is loaded successfully\")\n",
        "\n",
        "    return doc_list"
      ],
      "metadata": {
        "id": "DNRXRKqFe6OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_names = ['business','entertainment','politics','sport','tech']\n",
        "docs = load_data(folder_names=folder_names,root_path=os.getcwd())"
      ],
      "metadata": {
        "id": "rJTvF62PfL0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = pd.DataFrame(docs, columns = ['Category','Heading','Article'])"
      ],
      "metadata": {
        "id": "TiO-JzdefNlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs.head()"
      ],
      "metadata": {
        "id": "hO716FoofO_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs['text_len']=docs.Heading.apply(len)\n",
        "docs['headlines_len']=docs.Article.apply(len)"
      ],
      "metadata": {
        "id": "pjgB73GgfRno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs['Category'].value_counts().plot.bar()"
      ],
      "metadata": {
        "id": "YUKi2wuafTLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs.head()"
      ],
      "metadata": {
        "id": "kZUUYuXFgRQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "sns.histplot(docs.text_len, ax=axes[0], color='blue')\n",
        "sns.histplot(docs.headlines_len, ax=axes[1], color='red')"
      ],
      "metadata": {
        "id": "PSRzcfXWgS_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags_values = docs.Category.value_counts()\n",
        "tags_values"
      ],
      "metadata": {
        "id": "XCHBGf9ygWDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_boxplot(df, varibale):\n",
        "  fig1, ax1 = plt.subplots(figsize=(10,2))\n",
        "  ax1.set_title(f'BoxPlot of {variable}', fontsize=18)\n",
        "  values = list(df[variable].values)\n",
        "  ax1.boxplot(values, vert=False, showfliers=False, widths = 0.6);\n",
        "\n",
        "  bp_dict = boxplot(values, vert=False, showfliers=False, widths = 0.6)\n",
        "\n",
        "\n",
        "  for line in bp_dict['medians']:\n",
        "      # get position data for median line\n",
        "      x, y = line.get_xydata()[1] # top of median line\n",
        "      # overlay median value\n",
        "      text(x, y+0.05, '%.1f' % x,\n",
        "          horizontalalignment='center', fontsize=14) # draw above, centered\n",
        "\n",
        "  for line in bp_dict['whiskers']:\n",
        "      # get position data for median line\n",
        "      x, y = line.get_xydata()[1] # top of median line\n",
        "      # overlay median value\n",
        "      text(x, y+0.3, '%.1f' % x,\n",
        "          horizontalalignment='center', fontsize=14) # draw above, centered\n",
        "\n",
        "  for line in bp_dict['boxes']:\n",
        "      x, y = line.get_xydata()[0] # bottom of left line\n",
        "      text(x,y-0.02, '%.1f' % x,\n",
        "          horizontalalignment='center', # centered\n",
        "          verticalalignment='top', fontsize=14)      # below\n",
        "      x, y = line.get_xydata()[3] # bottom of right line\n",
        "      text(x,y-0.02, '%.1f' % x,\n",
        "          horizontalalignment='center', # centered\n",
        "              verticalalignment='top', fontsize=14)      # below\n",
        "\n",
        "  plt.xlabel(variable, fontsize=10)\n",
        "  plt.xticks(fontsize=8)\n",
        "  plt.yticks(fontsize=8)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "AEIfIFZbgb4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for variable in ['text_len','headlines_len']:\n",
        "  plot_boxplot(docs, variable)"
      ],
      "metadata": {
        "id": "BU3oR15Cgerp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a list of text belonging to individual category of articles\n",
        "\n",
        "heading_sport = docs[docs[\"Category\"]=='sport'][\"Heading\"] #Extracting the headings of the\n",
        "#print(heading_sport)\n",
        "collapsed_heading_sport =heading_sport.str.cat(sep = ' ') #\n",
        "#print(collapsed_heading_sport)\n",
        "\n",
        "heading_business = docs[docs[\"Category\"]=='business'][\"Heading\"] #Extracting the headings\n",
        "collapsed_heading_business =heading_business.str.cat(sep = ' ')\n",
        "\n",
        "heading_politics = docs[docs[\"Category\"]=='politics'][\"Heading\"]\n",
        "collapsed_heading_politics =heading_politics.str.cat(sep = ' ')\n",
        "\n",
        "heading_tech = docs[docs[\"Category\"]=='tech'][\"Heading\"]\n",
        "collapsed_heading_tech =heading_tech.str.cat(sep = ' ')\n",
        "\n",
        "heading_entertainment = docs[docs[\"Category\"]=='entertainment'][\"Heading\"]\n",
        "collapsed_heading_entertainment =heading_entertainment.str.cat(sep = ' ')"
      ],
      "metadata": {
        "id": "2LR5uXkYghKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating List of Stopwords\n",
        "stopwords = set(STOPWORDS)"
      ],
      "metadata": {
        "id": "9QmwVXAegjU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\033[1m'\"\\nSports\"'\\033[0m')\n",
        "#Generate a Word Cloud for Sports\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color='black', max_words=50).generate(collapsed_heading_sport)#Initializing the Word Cloud Class\n",
        "#Display the generated Word cloud as image\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('\\033[1m'\"\\nBusiness\"'\\033[0m')\n",
        "#Generate a Word Cloud for Business\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color='orange', max_words=50).generate(collapsed_heading_business)#Initializing the Word Cloud Class\n",
        "#Display the generated Word cloud as image\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uOel6nfMgk4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        " Finally, the transformed data is fed into a\n",
        " Multinomial Naive Bayes classifier to predict the\n",
        " category or label of the input text.\n",
        "\"\"\"\n",
        "#Building pipeline for raw text transformation\n",
        "clf = Pipeline([\n",
        "    ('vect', CountVectorizer(stop_words='english')),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('classifier', MultinomialNB()), #Apply the transformed data to Multinomial Naive Bayes Algo\n",
        "])"
      ],
      "metadata": {
        "id": "CmksHMdbgoFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(docs['Heading'],docs['Category'],\n",
        "                                                   random_state=42, test_size=0.2)\n",
        "print(f\"Size of input training data is {x_train.shape}\")\n",
        "print(f\"Size of input test data is {x_test.shape}\")\n",
        "print(f\"Size of output training data is {y_train.shape}\")\n",
        "print(f\"Size of output test data is {y_test.shape}\")"
      ],
      "metadata": {
        "id": "oVqfJvQugqSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = clf.fit(x_train,y_train) #fit the clf pipeline to training data"
      ],
      "metadata": {
        "id": "cHI82-dYgwLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy of the Naive Bayes Model\n",
        "mdl_score = \"{:.2f}\".format(model.score(x_test,y_test) * 100)\n",
        "print(f\"The Accuracy of the Naive Bayes Classifier Model is {mdl_score}%\")\n",
        "print(f\"\\n{mdl_score}% of the times the model predicts the correct category for the news article\")"
      ],
      "metadata": {
        "id": "WY5znbB2gyJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting on the test data\n",
        "y_pred_NB = model.predict(x_test)\n",
        "y_pred_NB[:5]\n"
      ],
      "metadata": {
        "id": "8RyM1tE_gzpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix to evaluate the accuracy of a classification\n",
        "cnf_mat = confusion_matrix(y_test,y_pred_NB)\n",
        "np.set_printoptions(precision=2)\n",
        "cnf_mat\n"
      ],
      "metadata": {
        "id": "c4jDDbAzg1XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm,classes,\n",
        "                          normalize = False,\n",
        "                          title = \"Confusion Matrix\",\n",
        "                          cmap = plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
        "        print(\"Normalized Confusion Matrix\")\n",
        "    else:\n",
        "        print(\"Confusion Matrix, without Normalization\")\n",
        "\n",
        "    print(cm)\n",
        "#show data as image using plt.imshow\n",
        "    plt.imshow(cm,interpolation='nearest',cmap = cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "#ARANGE : returns evenly spaced values from the given interval\n",
        "# and the advantage of numpy.arange() over the normal in-built range() function is that it allows us to generate sequences of numbers that are not integers\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation = 45)\n",
        "    plt.yticks(tick_marks,classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max()/2.\n",
        "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
        "        plt.text(j,i,format(cm[i,j],fmt),\n",
        "                 horizontalalignment = 'center',\n",
        "                 color = 'white' if cm[i,j] > thresh else 'black')\n",
        "\n",
        "    plt.xlabel = 'True Article Category'\n",
        "    plt.ylabel = 'Predicted Article Category'\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "0zSj6QIXg3Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Without Normalization\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_mat, classes=['business','entertainment','politics','sport','tech'],\n",
        "                      title='Confusion matrix, without normalization')\n",
        "# With normalization\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_mat,['business','entertainment','politics','sport','tech'], normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xrMI3U6Qg5M_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}